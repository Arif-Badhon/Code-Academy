Similar to how atoms are the building blocks of matter and how microprocessors are the building blocks of a computer, 
perceptrons are the building blocks of Neural Networks.

If you look closely, you might notice that the word “perceptron” is a combination of two words:

Perception (noun) the ability to sense something
Neuron (noun) a nerve cell in the human brain that turns sensory input into meaningful information
Therefore, the perceptron is an artificial neuron that simulates the task of a biological neuron to solve problems through its own “sense” of the world.

Although the perceptron comes with its own artificial design and set of parameters, at its core, a single perceptron is trying to make a simple decision.

Let’s take the example a simple self-driving car that is based on a perceptron. 
If there’s an obstacle on the left, the car would have to steer right. Similarly, if there’s an obstacle on the right, the car would have to steer left.

For this example, a perceptron could take the position of the obstacle as inputs, and produce a decision — left turn or right turn — based on those inputs.

And here’s the cool part — the perceptron can correct itself based on the result of its decision to make better decisions in the future!

Of course, the real world scenario isn’t that simple. But if you combine a bunch of such perceptrons, 
you will get a neural network that can even make better decisions on your behalf!
